{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurações iniciais\n",
        "previsao_dias = 15\n",
        "root_path = os.getcwd()\n",
        "minmaxcaler_5y = root_path + '/minmaxscaler_5y'\n",
        "lista = [a[2] for a in os.walk(minmaxcaler_5y)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparação dos dados\n",
        "total_mse_high = []\n",
        "total_mse_low = []\n",
        "count_files = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpSmdGCsCFno",
        "outputId": "69e58ed1-389b-424c-f85b-5ed54016c24c"
      },
      "outputs": [],
      "source": [
        "for arquivo in lista[0]:\n",
        "    df = pd.read_csv(os.path.join(minmaxcaler_5y, arquivo))\n",
        "    df = df.drop(columns=['Datetime'])\n",
        "    codigo = arquivo.split('_')[0]  # assumindo que o código da ação está no nome do arquivo\n",
        "\n",
        "    # Ajustando scalers\n",
        "    scaler_high = MinMaxScaler()\n",
        "    scaler_low = MinMaxScaler()\n",
        "    high_data = scaler_high.fit_transform(df[['High']])\n",
        "    low_data = scaler_low.fit_transform(df[['Low']])\n",
        "    combined_data = np.hstack((high_data, low_data))\n",
        "\n",
        "    training_size = int(len(combined_data) * 0.75)\n",
        "    train_data = combined_data[:training_size]\n",
        "    test_data = combined_data[training_size - previsao_dias:]\n",
        "\n",
        "    x_train, y_train, x_test, y_test = [], [], [], []\n",
        "\n",
        "    for i in range(previsao_dias, len(train_data)):\n",
        "        x_train.append(train_data[i-previsao_dias:i])\n",
        "        y_train.append(train_data[i])\n",
        "\n",
        "    for i in range(previsao_dias, len(test_data)):\n",
        "        x_test.append(test_data[i-previsao_dias:i])\n",
        "        y_test.append(test_data[i])\n",
        "\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "\n",
        "    # Modelo\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(100, return_sequences=False, input_shape=(previsao_dias, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(x_train, y_train, epochs=15, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    # Baixando dados reais\n",
        "    dados_reais = yf.download([codigo + \".SA\"], period = \"5y\", interval=\"1d\")\n",
        "    dados_reais = dados_reais.dropna(axis = 0)\n",
        "    dados = pd.DataFrame()\n",
        "    dados[\"Datetime\"] = dados_reais.index[:-1]\n",
        "\n",
        "    for colunas in [\"High\", \"Low\"]:\n",
        "      dados[colunas] = dados_reais[colunas].values[:-1]\n",
        "    reais_high = dados_reais['High'].values\n",
        "    reais_low = dados_reais['Low'].values\n",
        "\n",
        "\n",
        "    # Previsão e cálculo do MSE\n",
        "    predictions = model.predict(x_test)\n",
        "    highs_predictions_rescaled = scaler_high.inverse_transform(predictions[:, 0].reshape(-1, 1)).flatten()\n",
        "    lows_predictions_rescaled = scaler_low.inverse_transform(predictions[:, 1].reshape(-1, 1)).flatten()\n",
        "\n",
        "    print(highs_predictions_rescaled)\n",
        "\n",
        "    mse_high = mean_squared_error(reais_high[-len(highs_predictions_rescaled):], highs_predictions_rescaled)\n",
        "    mse_low = mean_squared_error(reais_low[-len(lows_predictions_rescaled):], lows_predictions_rescaled)\n",
        "\n",
        "    total_mse_high.append(mse_high)\n",
        "    total_mse_low.append(mse_low)\n",
        "\n",
        "    max_mse_high = max(total_mse_high)\n",
        "    max_mse_low = max(total_mse_low)\n",
        "\n",
        "    total_mse_high_normalized = [mse / max_mse_high for mse in total_mse_high]\n",
        "    total_mse_low_normalized = [mse / max_mse_low for mse in total_mse_low]\n",
        "\n",
        "print(total_mse_high_normalized)\n",
        "print(total_mse_low_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB8_TmA4KlEE",
        "outputId": "16c5e723-14be-47db-ee8c-754e1d194ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.48674881391877\n",
            "5.420316517125867\n"
          ]
        }
      ],
      "source": [
        "print(str(sum(total_mse_high_normalized)))\n",
        "print(str(sum(total_mse_low_normalized)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
